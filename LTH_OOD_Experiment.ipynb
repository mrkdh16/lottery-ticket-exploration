{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNYpQuNL7lraapHfpGJSaxP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrkdh16/lottery-ticket-exploration/blob/main/LTH_OOD_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, I aim to test the functional lottery ticket hypothesis presented in [Zhang et al](https://proceedings.mlr.press/v139/zhang21a/zhang21a.pdf): \"[for any full network] there exists a subnetwork that can achieve better OOD and commensurate in-distribution accuracy in a comparable number of iterations when trained in isolation\" using the [MNIST-1D dataset](https://github.com/greydanus/mnist1d?tab=readme-ov-file).\n",
        "\n",
        "Much of the code in this notebook is borrowed from an [example notebook](https://github.com/greydanus/mnist1d/blob/master/notebooks/lottery-tickets.ipynb) from the [MNIST-1D repo](https://github.com/greydanus/mnist1d?tab=readme-ov-file)."
      ],
      "metadata": {
        "id": "YdbXeDP18BM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install git+https://github.com/greydanus/mnist1d.git@master\n",
        "!git clone https://github.com/greydanus/mnist1d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bf5K3R6b8jrZ",
        "outputId": "482da59c-fc81-46cb-aee4-1e338f4820d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/greydanus/mnist1d.git@master\n",
            "  Cloning https://github.com/greydanus/mnist1d.git (to revision master) to /tmp/pip-req-build-0qidwzt0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/greydanus/mnist1d.git /tmp/pip-req-build-0qidwzt0\n",
            "  Resolved https://github.com/greydanus/mnist1d.git to commit 7878d96082abd200c546a07a4101fa90b30fdf7e\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from mnist1d==0.0.2.post16) (2.32.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from mnist1d==0.0.2.post16) (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mnist1d==0.0.2.post16) (3.10.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mnist1d==0.0.2.post16) (1.16.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mnist1d==0.0.2.post16) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->mnist1d==0.0.2.post16) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->mnist1d==0.0.2.post16) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->mnist1d==0.0.2.post16) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->mnist1d==0.0.2.post16) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mnist1d==0.0.2.post16) (1.17.0)\n",
            "Cloning into 'mnist1d'...\n",
            "remote: Enumerating objects: 541, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 541 (delta 120), reused 119 (delta 119), pack-reused 412 (from 1)\u001b[K\n",
            "Receiving objects: 100% (541/541), 14.54 MiB | 15.30 MiB/s, done.\n",
            "Resolving deltas: 100% (260/260), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "import torch, os\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import random\n",
        "\n",
        "# Try attaching to GPU\n",
        "DEVICE = str(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "print('Using:', DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhlcscQv-6cC",
        "outputId": "feb6fc7d-80bc-4fb3-8210-62ebdbed2d34"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if True:\n",
        "    # Only run this in Colab\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    project_dir = \"/content/gdrive/My Drive/Research/mnist1d/\"\n",
        "else:\n",
        "    project_dir = './'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dXPucEW-8uR",
        "outputId": "a6960d92-bcd4-4fc6-d23c-1f85014143fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from mnist1d.data import get_dataset, get_dataset_args, make_dataset\n",
        "from mnist1d.utils import set_seed, to_pickle, from_pickle\n",
        "\n",
        "import sys ; sys.path.append('./mnist1d/notebooks')\n",
        "from train import get_model_args, train_model"
      ],
      "metadata": {
        "id": "K350QfwG--Vm"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SparseLinear(torch.nn.Module):\n",
        "  def __init__(self, x_size, y_size):\n",
        "    super(SparseLinear, self).__init__()\n",
        "    self.linear = torch.nn.Linear(x_size, y_size)\n",
        "    param_vec = torch.cat([p.flatten() for p in self.parameters()])\n",
        "    self.mask = torch.ones_like(param_vec).to(DEVICE)\n",
        "\n",
        "  def forward(self, x, apply_mask=True):\n",
        "    if apply_mask:\n",
        "      self.apply_mask()\n",
        "    return self.linear(x)\n",
        "\n",
        "  def update_mask(self, new_mask):\n",
        "    self.mask = new_mask\n",
        "    self.apply_mask()\n",
        "\n",
        "  def apply_mask(self):\n",
        "    self.vec2param(self.param2vec())\n",
        "\n",
        "  def param2vec(self):\n",
        "    vec = torch.cat([p.flatten() for p in self.parameters()])\n",
        "    return self.mask * vec\n",
        "\n",
        "  def vec2param(self, vec):\n",
        "    pointer = 0\n",
        "    for param in self.parameters():\n",
        "      param_len = np.cumprod(param.shape)[-1]\n",
        "      new_param = vec[pointer:pointer+param_len].reshape(param.shape)\n",
        "      param.data = new_param.data\n",
        "      pointer += param_len\n",
        "\n",
        "class SparseMLP(torch.nn.Module):\n",
        "  def __init__(self, input_size, output_size, hidden_size=100):\n",
        "    super(SparseMLP, self).__init__()\n",
        "    self.linear1 = SparseLinear(input_size, hidden_size)\n",
        "    self.linear2 = SparseLinear(hidden_size, hidden_size)\n",
        "    self.linear3 = SparseLinear(hidden_size, output_size)\n",
        "    self.layers = [self.linear1, self.linear2, self.linear3]\n",
        "\n",
        "  def forward(self, x):\n",
        "    h = torch.relu(self.linear1(x))\n",
        "    h = h + torch.relu(self.linear2(h))\n",
        "    h = self.linear3(h)\n",
        "    return h\n",
        "\n",
        "  def get_layer_masks(self):\n",
        "    return [l.mask for l in self.layers]\n",
        "\n",
        "  def set_layer_masks(self, new_masks):\n",
        "    for i, l in enumerate(self.layers):\n",
        "      l.update_mask(new_masks[i])\n",
        "\n",
        "  def get_layer_vecs(self):\n",
        "    return [l.param2vec() for l in self.layers]\n",
        "\n",
        "  def set_layer_vecs(self, vecs):\n",
        "    for i, l in enumerate(self.layers):\n",
        "      l.vec2param(vecs[i])\n",
        "\n",
        "  # find a mask, given some heuristic and desired sparsity\n",
        "def get_mask(scores, percent_sparse):\n",
        "  # scores: per-weight scores for determining which weights to drop\n",
        "  # percent_sparse: how much to sparsify the model\n",
        "  num_to_drop = int(percent_sparse * len(scores))\n",
        "  ixs_to_drop = torch.sort(scores)[1][:num_to_drop] # sort from low score to high, select k with lowest score\n",
        "  mask = torch.ones_like(scores)\n",
        "  mask[ixs_to_drop] = 0\n",
        "  return mask"
      ],
      "metadata": {
        "id": "rSC00bYN_CBJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ],
      "metadata": {
        "id": "RJSNsOaHrJIt"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(model, inputs, targets):\n",
        "  preds = model(inputs).argmax(-1).cpu().numpy()\n",
        "  targets = targets.cpu().numpy().astype(np.float32)\n",
        "  return 100*sum(preds==targets)/len(targets)\n",
        "\n",
        "def train_model(dataset, model, args):\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.Adam(model.parameters(), args.learning_rate, weight_decay=args.weight_decay)\n",
        "\n",
        "  x_train, x_test = torch.Tensor(dataset['x']), torch.Tensor(dataset['x_test'])\n",
        "  y_train, y_test = torch.LongTensor(dataset['y']), torch.LongTensor(dataset['y_test'])\n",
        "\n",
        "  model = model.to(args.device)\n",
        "  x_train, x_test, y_train, y_test = [v.to(args.device) for v in [x_train, x_test, y_train, y_test]]\n",
        "\n",
        "  results = {'checkpoints':[], 'train_losses':[], 'test_losses':[],'train_acc':[],'test_acc':[]}\n",
        "  # t0 = time.time()\n",
        "  for step in range(args.total_steps+1):\n",
        "      bix = (step*args.batch_size)%len(x_train) # batch index\n",
        "      x, y = x_train[bix:bix+args.batch_size], y_train[bix:bix+args.batch_size]\n",
        "\n",
        "      loss = criterion(model(x), y)\n",
        "      results['train_losses'].append(loss.item())\n",
        "      loss.backward() ; optimizer.step() ; optimizer.zero_grad()\n",
        "\n",
        "      if args.eval_every > 0 and step % args.eval_every == 0: # evaluate the model\n",
        "          test_loss = criterion(model(x_test), y_test)\n",
        "          results['test_losses'].append(test_loss.item())\n",
        "          results['train_acc'].append(accuracy(model, x_train, y_train))\n",
        "          results['test_acc'].append(accuracy(model, x_test, y_test))\n",
        "\n",
        "      # if step > 0 and step % args.print_every == 0: # print out training progress\n",
        "      #     t1 = time.time()\n",
        "      #     print(\"step {}, dt {:.2f}s, train_loss {:.3e}, test_loss {:.3e}, train_acc {:.1f}, test_acc {:.1f}\"\n",
        "      #         .format(step, t1-t0, loss.item(), results['test_losses'][-1], \\\n",
        "      #                 results['train_acc'][-1], results['test_acc'][-1]))\n",
        "      #     t0 = t1\n",
        "\n",
        "      # if args.checkpoint_every > 0 and step % args.checkpoint_every == 0: # save model checkpoints\n",
        "      #     model.step = step\n",
        "      #     results['checkpoints'].append( copy.deepcopy(model) )\n",
        "  return results"
      ],
      "metadata": {
        "id": "zUU_7LT4qei7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_lottery_ticket(model, dataset, args, sparsity_schedule, criteria_fn=None,\n",
        "                        prune_print_every=None, seed=None, **kwargs):\n",
        "  if seed is not None:\n",
        "    set_seed(seed)\n",
        "\n",
        "  if prune_print_every is None:\n",
        "    prune_print_every = np.inf\n",
        "\n",
        "  if criteria_fn is None:\n",
        "    print(\"Using default magnitude-based pruning\")\n",
        "    criteria_fn = lambda init_params, final_params: final_params.abs()\n",
        "\n",
        "  init_params = model.get_layer_vecs()\n",
        "  stats = {'train_losses':[], 'test_losses':[], 'train_accs':[], 'test_accs':[]}\n",
        "  models = []\n",
        "  for i, percent_sparse in enumerate(sparsity_schedule):\n",
        "\n",
        "    # layer-wise pruning, where pruning heuristic is determined by criteria_fn\n",
        "    final_params = model.get_layer_vecs()\n",
        "    scores = [criteria_fn(ip, fp) for ip, fp in zip(init_params, final_params)]\n",
        "    masks = [get_mask(s, percent_sparse) for s in scores]\n",
        "\n",
        "    # update model with mask and init parameters\n",
        "    model.set_layer_vecs(init_params)\n",
        "    model.set_layer_masks(masks)\n",
        "\n",
        "    # training process\n",
        "    results = train_model(dataset, model, args)\n",
        "    model = results['checkpoints'][-1]\n",
        "\n",
        "    # store stats\n",
        "    stats['train_losses'].append(results['train_losses'])\n",
        "    stats['test_losses'].append(results['test_losses'])\n",
        "    stats['train_accs'].append(results['train_acc'])\n",
        "    stats['test_accs'].append(results['test_acc'])\n",
        "\n",
        "    # print progress\n",
        "    if (i+1) % prune_print_every == 0:\n",
        "      print('\\tretrain #{}, sparsity {:.2f}, final_train_loss {:.3e}, max_acc {:.1f}, last_acc {:.1f}, mean_acc {:.1f}'\n",
        "            .format(i+1, percent_sparse, results['train_losses'][-1], np.max(results['test_acc']),\n",
        "            results['test_acc'][-1], np.mean(results['test_acc']) ))\n",
        "      models.append(copy.deepcopy(model))\n",
        "\n",
        "  stats = {k: np.stack(v) for k, v in stats.items()}\n",
        "  return models, stats"
      ],
      "metadata": {
        "id": "UaEtaEK6pgsI"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train settings\n",
        "model_args = get_model_args()\n",
        "model_args.total_steps = 1501\n",
        "model_args.hidden_size = 500\n",
        "model_args.print_every = 5000 # print never\n",
        "model_args.eval_every = 100\n",
        "model_args.learning_rate = 2e-2\n",
        "model_args.device = DEVICE\n",
        "\n",
        "# sparsity settings\n",
        "num_retrains = 100\n",
        "sparsity_schedule = np.linspace(0,1.,num_retrains) #1-np.cumprod(np.ones(num_retrains)*tau)/tau # tau = .97"
      ],
      "metadata": {
        "id": "gH60zzJrpqCA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_trials = 2\n",
        "trials = {'rand_models': [], 'rand_stats': [], 'lott_models': [], 'lott_stats': []}\n",
        "for t in range(num_trials):\n",
        "  print(\"############  Trial {}  ############\".format(t))\n",
        "  set_seed(model_args.seed+t)\n",
        "  model = SparseMLP(model_args.input_size, model_args.output_size, hidden_size=model_args.hidden_size).to(DEVICE)\n",
        "\n",
        "  criteria_fn = lambda init_params, final_params: final_params.abs()\n",
        "  models, stats = find_lottery_ticket(model, data, model_args, sparsity_schedule,\n",
        "                  criteria_fn=criteria_fn, prune_print_every=1)\n",
        "  trials['lott_models'].append(models)\n",
        "  trials['lott_stats'].append(stats)"
      ],
      "metadata": {
        "id": "A2ZXJsa7qZcL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}